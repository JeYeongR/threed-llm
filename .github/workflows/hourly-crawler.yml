name: 시간별 블로그 크롤링

on:
  schedule:
    # 매시간 정각마다 실행
    - cron: "0 * * * *"
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: 코드 체크아웃
        uses: actions/checkout@v3

      - name: Python 설정
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: 의존성 설치
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: SSH 키 설정
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > threed.pem
          chmod 600 threed.pem

      - name: .env 파일 설정
        env:
          ENV_FILE: ${{ secrets.ENV_FILE }}
        run: |
          echo "$ENV_FILE" > .env

      - name: 크롤링 실행
        run: python run.py > crawler.log 2>&1

      - name: 로그 업로드
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: crawler-logs
          path: |
            *.log
          retention-days: 3
